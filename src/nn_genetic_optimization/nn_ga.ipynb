{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 0\n"
     ]
    }
   ],
   "source": [
    "import setGPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import json\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc, f1_score\n",
    "\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_GENERATIONS = 10\n",
    "POPULATION_SIZE = 30\n",
    "MUTATION_RATE = 0.1\n",
    "N_LAYERS = 3\n",
    "\n",
    "NN_PARAM_CHOICES = {\n",
    "    \"layer\": {\n",
    "        \"units\": [25, 50, 100, 200, 250],\n",
    "        \"activation\": [\"relu\", \"elu\", \"sigmoid\", \"tanh\"],\n",
    "        \"dropout\": [0.0, 0.25, 0.5]\n",
    "    },\n",
    "    \"network\":{\n",
    "        \"nlayers\": [1, 2, 3, 4],\n",
    "        \"optimizer\": [\"adam\", \"rmsprop\"]\n",
    "    }    \n",
    "}\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_acc', patience=5, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetworkLayer(object):\n",
    "    def __init__(self, units=50, activation=\"relu\", dropout=0.1):\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.dropout = dropout\n",
    "    \n",
    "    def to_json(self):\n",
    "        \"\"\" Returns dict \"\"\"\n",
    "        return {attr: getattr(self, attr) for attr in NetworkLayer.attrs()}\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"({units} {activation} ({dropout}))\".format(units=self.units, activation=self.activation, dropout=self.dropout)\n",
    "    \n",
    "    @staticmethod\n",
    "    def attrs():\n",
    "        return (\"units\", \"activation\", \"dropout\")\n",
    "        \n",
    "class Network(object):\n",
    "    def __init__(self, optimizer=\"adam\"):\n",
    "        \n",
    "        # Network parameters\n",
    "        self.layers = []\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # Model\n",
    "        self.model = Sequential()\n",
    "        self.history = None\n",
    "        \n",
    "        # Score\n",
    "        self.confusion_matrix = None\n",
    "        self.accuracy = None\n",
    "        self.f1 = None\n",
    "        self.fpr = None\n",
    "        self.tpr = None\n",
    "        self.auc = None\n",
    "        \n",
    "    def __eq__(self, other):\n",
    "        \"\"\" Compares if network is equal to other network\n",
    "        \"\"\"\n",
    "        \n",
    "        # Optimizer must match\n",
    "        if self.optimizer != other.optimizer:\n",
    "            return False\n",
    "        \n",
    "        # Number of network layers\n",
    "        nlayers = len(self.layers)\n",
    "        if nlayers != len(other.layers):\n",
    "            return False\n",
    "        \n",
    "        # Compare all layers\n",
    "        for n in range(nlayers):\n",
    "            # Compare all attributes of the NetworkLayer\n",
    "            for attr in NetworkLayer.attrs():\n",
    "                if getattr(self.layers[n], attr) != getattr(other.layers[n], attr):\n",
    "                    return False\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    \n",
    "    def compile_model(self, input_shape=(2807,)):\n",
    "        \"\"\" Creates model from network parameters and compiles it \"\"\"\n",
    "        \n",
    "        for index, layer in enumerate(self.layers):\n",
    "\n",
    "            if index == 0:\n",
    "                self.model.add(Dense(units=layer.units, activation=layer.activation, input_shape=input_shape))\n",
    "            else:\n",
    "                self.model.add(Dense(units=layer.units, activation=layer.activation))\n",
    "\n",
    "            self.model.add(Dropout(layer.dropout))  \n",
    "\n",
    "        # Output\n",
    "        self.model.add(Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "        self.model.compile(optimizer=self.optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        \"\"\" Train model\"\"\"\n",
    "        \n",
    "        if self.history is not None:\n",
    "            # Do not retrain already trained model\n",
    "            return\n",
    "        \n",
    "        self.history = self.model.fit(X_train, y_train, \n",
    "                        validation_split=0.25, \n",
    "                        epochs=10000, \n",
    "                        callbacks=[earlystop],\n",
    "                        batch_size=100, \n",
    "                        verbose=0, \n",
    "                        class_weight=cw)\n",
    "        \n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\" Evaluates model: calculates accuracy, f1score, roc_auc curves, confusion matrix\"\"\"\n",
    "        # Accuracy and f1_score\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_pred = (y_pred > 0.5)\n",
    "        \n",
    "        self.confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "        self.accuracy = accuracy_score(y_test, y_pred)\n",
    "        self.f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "        # ROC AUC\n",
    "        y_probas = self.model.predict_proba(X_test, verbose=0)\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_probas)\n",
    "        self.auc = auc(fpr, tpr)\n",
    "        \n",
    "        self.fpr = fpr\n",
    "        self.tpr = tpr\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Layers: {nlayers} {layers}, Optimizer: {optimizer}, Accuracy {accuracy}, AUC {auc}\".format(\n",
    "            nlayers=len(self.layers), \n",
    "            layers=self.layers, \n",
    "            optimizer=self.optimizer, \n",
    "            accuracy=round(self.accuracy, 3) if self.accuracy else None, \n",
    "            auc=round(self.auc, 3) if self.auc else None\n",
    "        )\n",
    "    \n",
    "    def to_json(self):\n",
    "        \"\"\" Returns dict \"\"\"\n",
    "        \n",
    "        j = {\n",
    "            \"score\": {\n",
    "                \"accuracy\": self.accuracy,\n",
    "                \"f1\": self.f1,\n",
    "                \"auc\": self.auc,\n",
    "            },\n",
    "            \"layers\": []\n",
    "        }\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            j[\"layers\"].append(layer.to_json())\n",
    "        \n",
    "        return j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(163684, 2813)\n"
     ]
    }
   ],
   "source": [
    "dset = None\n",
    "\n",
    "filename = \"/home/mantas/data/JetHT2016.h5\"\n",
    "\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    dset = f[\"JetHT2016\"][:] \n",
    "        \n",
    "print(dset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dset[:, :2807] # 2807 features\n",
    "y = dset[:, 2812]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = StandardScaler(copy=False).fit_transform(X) # copy=False reduce memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate class weights and class balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0 Count 3041 Weight 26.912857612627427\n",
      "Class 1 Count 160643 Weight 0.5094650871808918\n",
      "{0: 26.912857612627427, 1: 0.5094650871808918}\n"
     ]
    }
   ],
   "source": [
    "classes, counts = np.unique(y, return_counts=True)\n",
    "weights = class_weight.compute_class_weight('balanced', classes, y)\n",
    "cw = {}\n",
    "for _class, _weight, _count in zip(classes, weights, counts):\n",
    "    _class = int(_class)\n",
    "    cw[_class] = _weight\n",
    "    print(\"Class {_class} Count {_count} Weight {_weight}\".format(_class=_class, _count=_count, _weight=_weight))\n",
    "print(cw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_history = []\n",
    "population = []\n",
    "\n",
    "\n",
    "network1 = Network(optimizer=\"adam\")\n",
    "network1.layers.append(NetworkLayer(250, \"elu\", 0.5))\n",
    "network1.layers.append(NetworkLayer(50, \"elu\", 0.25))\n",
    "network1.layers.append(NetworkLayer(15, \"elu\", 0.25))\n",
    "network1.compile_model()\n",
    "\n",
    "network2 = Network(optimizer=\"adam\")\n",
    "network2.layers.append(NetworkLayer(50, \"elu\", 0.5))\n",
    "network2.layers.append(NetworkLayer(250, \"elu\", 0.25))\n",
    "network2.layers.append(NetworkLayer(55, \"elu\", 0.5))\n",
    "network2.compile_model()\n",
    "\n",
    "network3 = Network(optimizer=\"adam\")\n",
    "network3.layers.append(NetworkLayer(250, \"elu\", 0.25))\n",
    "network3.layers.append(NetworkLayer(200, \"elu\", 0.0))\n",
    "network3.layers.append(NetworkLayer(100, \"elu\", 0.25))\n",
    "network3.compile_model()\n",
    "\n",
    "population.append(network1)\n",
    "population.append(network2)\n",
    "population.append(network3)\n",
    "\n",
    "while len(population) < POPULATION_SIZE:\n",
    "    \n",
    "    network = Network()\n",
    "    network.optimizer = random.choice(NN_PARAM_CHOICES[\"network\"][\"optimizer\"])\n",
    "    \n",
    "    for n in range(N_LAYERS):\n",
    "        layer = NetworkLayer()\n",
    "        for attr in NetworkLayer.attrs():\n",
    "            value = random.choice(NN_PARAM_CHOICES[\"layer\"][attr])\n",
    "            setattr(layer, attr, value)\n",
    "            \n",
    "        network.layers.append(layer)\n",
    "        \n",
    "    network.compile_model()\n",
    "    \n",
    "    population.append(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers: 3 [(250 elu (0.5)), (50 elu (0.25)), (15 elu (0.25))], Optimizer: adam, Accuracy None, AUC None\n",
      "Layers: 3 [(50 elu (0.5)), (250 elu (0.25)), (55 elu (0.5))], Optimizer: adam, Accuracy None, AUC None\n",
      "Layers: 3 [(250 elu (0.25)), (200 elu (0.0)), (100 elu (0.25))], Optimizer: adam, Accuracy None, AUC None\n",
      "Layers: 3 [(200 relu (0.0)), (100 elu (0.25)), (250 sigmoid (0.25))], Optimizer: rmsprop, Accuracy None, AUC None\n",
      "Layers: 3 [(200 elu (0.25)), (200 sigmoid (0.5)), (250 relu (0.5))], Optimizer: adam, Accuracy None, AUC None\n",
      "Layers: 3 [(250 relu (0.0)), (100 tanh (0.0)), (25 elu (0.0))], Optimizer: adam, Accuracy None, AUC None\n",
      "Layers: 3 [(100 tanh (0.25)), (50 tanh (0.0)), (25 relu (0.5))], Optimizer: rmsprop, Accuracy None, AUC None\n",
      "Layers: 3 [(25 elu (0.25)), (250 relu (0.25)), (200 sigmoid (0.25))], Optimizer: rmsprop, Accuracy None, AUC None\n",
      "Layers: 3 [(250 tanh (0.5)), (50 tanh (0.25)), (25 relu (0.5))], Optimizer: adam, Accuracy None, AUC None\n",
      "Layers: 3 [(100 elu (0.25)), (25 relu (0.5)), (100 sigmoid (0.5))], Optimizer: rmsprop, Accuracy None, AUC None\n",
      "Layers: 3 [(250 elu (0.0)), (100 sigmoid (0.5)), (200 elu (0.5))], Optimizer: rmsprop, Accuracy None, AUC None\n",
      "Layers: 3 [(50 elu (0.5)), (100 relu (0.5)), (50 relu (0.0))], Optimizer: adam, Accuracy None, AUC None\n",
      "Layers: 3 [(25 elu (0.5)), (50 elu (0.5)), (25 sigmoid (0.25))], Optimizer: rmsprop, Accuracy None, AUC None\n",
      "Layers: 3 [(250 tanh (0.25)), (25 tanh (0.0)), (250 elu (0.25))], Optimizer: rmsprop, Accuracy None, AUC None\n",
      "Layers: 3 [(50 sigmoid (0.25)), (100 relu (0.0)), (50 elu (0.25))], Optimizer: rmsprop, Accuracy None, AUC None\n",
      "Layers: 3 [(200 tanh (0.25)), (25 tanh (0.25)), (25 tanh (0.0))], Optimizer: adam, Accuracy None, AUC None\n",
      "Layers: 3 [(50 relu (0.5)), (200 tanh (0.25)), (250 sigmoid (0.25))], Optimizer: rmsprop, Accuracy None, AUC None\n",
      "Layers: 3 [(50 tanh (0.5)), (100 tanh (0.0)), (25 sigmoid (0.25))], Optimizer: rmsprop, Accuracy None, AUC None\n",
      "Layers: 3 [(100 tanh (0.25)), (50 tanh (0.5)), (100 tanh (0.0))], Optimizer: adam, Accuracy None, AUC None\n",
      "Layers: 3 [(100 tanh (0.0)), (250 sigmoid (0.0)), (25 elu (0.0))], Optimizer: rmsprop, Accuracy None, AUC None\n",
      "Layers: 3 [(50 sigmoid (0.25)), (25 relu (0.25)), (25 relu (0.25))], Optimizer: adam, Accuracy None, AUC None\n",
      "Layers: 3 [(250 tanh (0.5)), (50 elu (0.25)), (250 relu (0.25))], Optimizer: rmsprop, Accuracy None, AUC None\n",
      "Layers: 3 [(250 relu (0.5)), (200 elu (0.0)), (25 relu (0.0))], Optimizer: rmsprop, Accuracy None, AUC None\n",
      "Layers: 3 [(50 tanh (0.0)), (25 sigmoid (0.5)), (200 sigmoid (0.0))], Optimizer: rmsprop, Accuracy None, AUC None\n",
      "Layers: 3 [(25 sigmoid (0.5)), (50 tanh (0.5)), (50 relu (0.25))], Optimizer: adam, Accuracy None, AUC None\n",
      "Layers: 3 [(250 elu (0.25)), (250 relu (0.25)), (100 sigmoid (0.5))], Optimizer: rmsprop, Accuracy None, AUC None\n",
      "Layers: 3 [(250 relu (0.25)), (50 tanh (0.5)), (250 elu (0.25))], Optimizer: rmsprop, Accuracy None, AUC None\n",
      "Layers: 3 [(250 relu (0.5)), (200 elu (0.0)), (200 sigmoid (0.25))], Optimizer: rmsprop, Accuracy None, AUC None\n",
      "Layers: 3 [(25 elu (0.25)), (200 tanh (0.5)), (100 relu (0.0))], Optimizer: adam, Accuracy None, AUC None\n",
      "Layers: 3 [(200 tanh (0.25)), (200 relu (0.0)), (200 relu (0.0))], Optimizer: adam, Accuracy None, AUC None\n"
     ]
    }
   ],
   "source": [
    "for network in population:\n",
    "    print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossover(parent1, parent2, mutation_rate=0.1):\n",
    "    \"\"\" Crossover parameters of two parents\n",
    "        Return child network\n",
    "    \"\"\"\n",
    "    nlayers = len(parent1.layers)\n",
    "    if nlayers != len(parent2.layers):\n",
    "        # Number of layers must match\n",
    "        return \n",
    "\n",
    "    child = Network()\n",
    "    \n",
    "    child.optimizer = random.choice([parent1.optimizer, parent2.optimizer])\n",
    "\n",
    "    for n in range(nlayers):\n",
    "        \n",
    "        units = random.choice([parent1.layers[n].units, parent2.layers[n].units])\n",
    "        activation = random.choice([parent1.layers[n].activation, parent2.layers[n].activation])\n",
    "        dropout = random.choice([parent1.layers[n].dropout, parent2.layers[n].dropout])\n",
    "        \n",
    "        layer = NetworkLayer(units, activation, dropout)\n",
    "        \n",
    "        if MUTATION_RATE < random.random():\n",
    "            mutation_key = random.choice(list(NN_PARAM_CHOICES[\"layer\"].keys()))\n",
    "            mutation_val = random.choice(NN_PARAM_CHOICES[\"layer\"][mutation_key])\n",
    "#             print(\"mutation \", mutation_key, mutation_val)\n",
    "            setattr(layer, mutation_key, mutation_val)\n",
    "            \n",
    "        child.layers.append(layer)\n",
    "    \n",
    "    return child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(population):\n",
    "    for index, network in enumerate(population):\n",
    "        print(\"Training #{}\".format(index))\n",
    "        network.train(X_train, y_train)\n",
    "        network.score(X_test, y_test)\n",
    "        print(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, breed, mutate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0\n",
      "Training #0\n",
      "Epoch 00014: early stopping\n",
      "Layers: 3 [(250 elu (0.5)), (50 elu (0.25)), (15 elu (0.25))], Optimizer: adam, Accuracy 0.981, AUC 0.959\n",
      "Training #1\n",
      "Epoch 00015: early stopping\n",
      "Layers: 3 [(50 elu (0.5)), (250 elu (0.25)), (55 elu (0.5))], Optimizer: adam, Accuracy 0.982, AUC 0.962\n",
      "Training #2\n",
      "Epoch 00010: early stopping\n",
      "Layers: 3 [(250 elu (0.25)), (200 elu (0.0)), (100 elu (0.25))], Optimizer: adam, Accuracy 0.982, AUC 0.961\n",
      "Training #3\n",
      "Epoch 00021: early stopping\n",
      "Layers: 3 [(200 relu (0.0)), (100 elu (0.25)), (250 sigmoid (0.25))], Optimizer: rmsprop, Accuracy 0.99, AUC 0.79\n",
      "Training #4\n",
      "Epoch 00009: early stopping\n",
      "Layers: 3 [(200 elu (0.25)), (200 sigmoid (0.5)), (250 relu (0.5))], Optimizer: adam, Accuracy 0.912, AUC 0.963\n",
      "Training #5\n",
      "Epoch 00009: early stopping\n",
      "Layers: 3 [(250 relu (0.0)), (100 tanh (0.0)), (25 elu (0.0))], Optimizer: adam, Accuracy 0.974, AUC 0.961\n",
      "Training #6\n",
      "Epoch 00013: early stopping\n",
      "Layers: 3 [(100 tanh (0.25)), (50 tanh (0.0)), (25 relu (0.5))], Optimizer: rmsprop, Accuracy 0.964, AUC 0.963\n",
      "Training #7\n",
      "Epoch 00007: early stopping\n",
      "Layers: 3 [(25 elu (0.25)), (250 relu (0.25)), (200 sigmoid (0.25))], Optimizer: rmsprop, Accuracy 0.979, AUC 0.903\n",
      "Training #8\n",
      "Epoch 00017: early stopping\n",
      "Layers: 3 [(250 tanh (0.5)), (50 tanh (0.25)), (25 relu (0.5))], Optimizer: adam, Accuracy 0.963, AUC 0.963\n",
      "Training #9\n",
      "Epoch 00012: early stopping\n",
      "Layers: 3 [(100 elu (0.25)), (25 relu (0.5)), (100 sigmoid (0.5))], Optimizer: rmsprop, Accuracy 0.99, AUC 0.821\n",
      "Training #10\n",
      "Epoch 00012: early stopping\n",
      "Layers: 3 [(250 elu (0.0)), (100 sigmoid (0.5)), (200 elu (0.5))], Optimizer: rmsprop, Accuracy 0.985, AUC 0.914\n",
      "Training #11\n",
      "Epoch 00019: early stopping\n",
      "Layers: 3 [(50 elu (0.5)), (100 relu (0.5)), (50 relu (0.0))], Optimizer: adam, Accuracy 0.979, AUC 0.962\n",
      "Training #12\n",
      "Epoch 00020: early stopping\n",
      "Layers: 3 [(25 elu (0.5)), (50 elu (0.5)), (25 sigmoid (0.25))], Optimizer: rmsprop, Accuracy 0.992, AUC 0.805\n",
      "Training #13\n",
      "Epoch 00016: early stopping\n",
      "Layers: 3 [(250 tanh (0.25)), (25 tanh (0.0)), (250 elu (0.25))], Optimizer: rmsprop, Accuracy 0.984, AUC 0.945\n",
      "Training #14\n",
      "Epoch 00009: early stopping\n",
      "Layers: 3 [(50 sigmoid (0.25)), (100 relu (0.0)), (50 elu (0.25))], Optimizer: rmsprop, Accuracy 0.972, AUC 0.957\n",
      "Training #15\n",
      "Epoch 00018: early stopping\n",
      "Layers: 3 [(200 tanh (0.25)), (25 tanh (0.25)), (25 tanh (0.0))], Optimizer: adam, Accuracy 0.963, AUC 0.964\n",
      "Training #16\n",
      "Epoch 00013: early stopping\n",
      "Layers: 3 [(50 relu (0.5)), (200 tanh (0.25)), (250 sigmoid (0.25))], Optimizer: rmsprop, Accuracy 0.991, AUC 0.799\n",
      "Training #17\n",
      "Epoch 00011: early stopping\n",
      "Layers: 3 [(50 tanh (0.5)), (100 tanh (0.0)), (25 sigmoid (0.25))], Optimizer: rmsprop, Accuracy 0.974, AUC 0.941\n",
      "Training #18\n",
      "Epoch 00026: early stopping\n",
      "Layers: 3 [(100 tanh (0.25)), (50 tanh (0.5)), (100 tanh (0.0))], Optimizer: adam, Accuracy 0.971, AUC 0.96\n",
      "Training #19\n",
      "Epoch 00015: early stopping\n",
      "Layers: 3 [(100 tanh (0.0)), (250 sigmoid (0.0)), (25 elu (0.0))], Optimizer: rmsprop, Accuracy 0.974, AUC 0.95\n",
      "Training #20\n",
      "Epoch 00022: early stopping\n",
      "Layers: 3 [(50 sigmoid (0.25)), (25 relu (0.25)), (25 relu (0.25))], Optimizer: adam, Accuracy 0.979, AUC 0.964\n",
      "Training #21\n",
      "Epoch 00015: early stopping\n",
      "Layers: 3 [(250 tanh (0.5)), (50 elu (0.25)), (250 relu (0.25))], Optimizer: rmsprop, Accuracy 0.968, AUC 0.952\n",
      "Training #22\n",
      "Epoch 00027: early stopping\n",
      "Layers: 3 [(250 relu (0.5)), (200 elu (0.0)), (25 relu (0.0))], Optimizer: rmsprop, Accuracy 0.991, AUC 0.786\n",
      "Training #23\n",
      "Epoch 00017: early stopping\n",
      "Layers: 3 [(50 tanh (0.0)), (25 sigmoid (0.5)), (200 sigmoid (0.0))], Optimizer: rmsprop, Accuracy 0.976, AUC 0.951\n",
      "Training #24\n",
      "Epoch 00013: early stopping\n",
      "Layers: 3 [(25 sigmoid (0.5)), (50 tanh (0.5)), (50 relu (0.25))], Optimizer: adam, Accuracy 0.969, AUC 0.963\n",
      "Training #25\n",
      "Epoch 00009: early stopping\n",
      "Layers: 3 [(250 elu (0.25)), (250 relu (0.25)), (100 sigmoid (0.5))], Optimizer: rmsprop, Accuracy 0.992, AUC 0.824\n",
      "Training #26\n",
      "Epoch 00012: early stopping\n",
      "Layers: 3 [(250 relu (0.25)), (50 tanh (0.5)), (250 elu (0.25))], Optimizer: rmsprop, Accuracy 0.991, AUC 0.79\n",
      "Training #27\n",
      "Epoch 00009: early stopping\n",
      "Layers: 3 [(250 relu (0.5)), (200 elu (0.0)), (200 sigmoid (0.25))], Optimizer: rmsprop, Accuracy 0.992, AUC 0.803\n",
      "Training #28\n",
      "Epoch 00015: early stopping\n",
      "Layers: 3 [(25 elu (0.25)), (200 tanh (0.5)), (100 relu (0.0))], Optimizer: adam, Accuracy 0.964, AUC 0.962\n",
      "Training #29\n",
      "Epoch 00008: early stopping\n",
      "Layers: 3 [(200 tanh (0.25)), (200 relu (0.0)), (200 relu (0.0))], Optimizer: adam, Accuracy 0.966, AUC 0.96\n",
      "Best:\n",
      "Layers: 3 [(50 sigmoid (0.25)), (25 relu (0.25)), (25 relu (0.25))], Optimizer: adam, Accuracy 0.979, AUC 0.964\n",
      "Layers: 3 [(200 tanh (0.25)), (25 tanh (0.25)), (25 tanh (0.0))], Optimizer: adam, Accuracy 0.963, AUC 0.964\n",
      "Layers: 3 [(200 elu (0.25)), (200 sigmoid (0.5)), (250 relu (0.5))], Optimizer: adam, Accuracy 0.912, AUC 0.963\n",
      "Generation 1\n",
      "Training #0\n",
      "Epoch 00016: early stopping\n",
      "Layers: 3 [(50 elu (0.25)), (25 relu (0.25)), (25 sigmoid (0.25))], Optimizer: adam, Accuracy 0.961, AUC 0.967\n",
      "Training #1\n",
      "Epoch 00007: early stopping\n",
      "Layers: 3 [(100 sigmoid (0.25)), (250 relu (0.25)), (25 tanh (0.5))], Optimizer: adam, Accuracy 0.97, AUC 0.969\n",
      "Training #2\n",
      "Epoch 00017: early stopping\n",
      "Layers: 3 [(250 sigmoid (0.5)), (50 tanh (0.25)), (200 relu (0.25))], Optimizer: adam, Accuracy 0.979, AUC 0.966\n",
      "Training #3\n",
      "Epoch 00020: early stopping\n",
      "Layers: 3 [(200 relu (0.25)), (250 sigmoid (0.5)), (250 elu (0.5))], Optimizer: adam, Accuracy 0.978, AUC 0.959\n",
      "Training #4\n",
      "Epoch 00012: early stopping\n",
      "Layers: 3 [(100 sigmoid (0.25)), (50 sigmoid (0.0)), (250 relu (0.25))], Optimizer: rmsprop, Accuracy 0.982, AUC 0.959\n",
      "Training #5\n",
      "Epoch 00007: early stopping\n",
      "Layers: 3 [(250 relu (0.5)), (50 elu (0.25)), (25 tanh (0.0))], Optimizer: adam, Accuracy 0.954, AUC 0.958\n",
      "Training #6\n",
      "Epoch 00019: early stopping\n",
      "Layers: 3 [(50 sigmoid (0.0)), (25 relu (0.25)), (25 relu (0.0))], Optimizer: adam, Accuracy 0.975, AUC 0.954\n",
      "Training #7\n",
      "Epoch 00011: early stopping\n",
      "Layers: 3 [(50 tanh (0.25)), (50 tanh (0.0)), (25 tanh (0.25))], Optimizer: rmsprop, Accuracy 0.972, AUC 0.954\n",
      "Training #8\n",
      "Epoch 00014: early stopping\n",
      "Layers: 3 [(200 sigmoid (0.0)), (50 sigmoid (0.5)), (50 relu (0.25))], Optimizer: adam, Accuracy 0.97, AUC 0.956\n",
      "Training #9\n",
      "Epoch 00017: early stopping\n",
      "Layers: 3 [(50 elu (0.25)), (25 elu (0.0)), (25 relu (0.25))], Optimizer: adam, Accuracy 0.984, AUC 0.963\n",
      "Training #10\n",
      "Epoch 00011: early stopping\n",
      "Layers: 3 [(25 elu (0.25)), (200 sigmoid (0.5)), (200 relu (0.25))], Optimizer: adam, Accuracy 0.965, AUC 0.967\n",
      "Training #11\n",
      "Epoch 00017: early stopping\n",
      "Layers: 3 [(50 tanh (0.25)), (50 tanh (0.25)), (100 relu (0.5))], Optimizer: adam, Accuracy 0.956, AUC 0.959\n",
      "Training #12\n",
      "Epoch 00017: early stopping\n",
      "Layers: 3 [(200 tanh (0.25)), (25 tanh (0.25)), (100 elu (0.0))], Optimizer: adam, Accuracy 0.967, AUC 0.961\n",
      "Training #13\n",
      "Epoch 00016: early stopping\n",
      "Layers: 3 [(100 elu (0.25)), (100 tanh (0.25)), (100 sigmoid (0.0))], Optimizer: adam, Accuracy 0.97, AUC 0.964\n",
      "Training #14\n",
      "Epoch 00022: early stopping\n",
      "Layers: 3 [(100 tanh (0.25)), (200 tanh (0.5)), (25 relu (0.5))], Optimizer: adam, Accuracy 0.968, AUC 0.961\n",
      "Training #15\n",
      "Epoch 00007: early stopping\n",
      "Layers: 3 [(100 tanh (0.0)), (50 tanh (0.5)), (25 relu (0.5))], Optimizer: rmsprop, Accuracy 0.943, AUC 0.948\n",
      "Training #16\n",
      "Epoch 00011: early stopping\n",
      "Layers: 3 [(200 elu (0.0)), (50 tanh (0.5)), (250 sigmoid (0.25))], Optimizer: adam, Accuracy 0.968, AUC 0.965\n",
      "Training #17\n",
      "Epoch 00020: early stopping\n",
      "Layers: 3 [(250 tanh (0.5)), (25 tanh (0.5)), (25 elu (0.25))], Optimizer: adam, Accuracy 0.948, AUC 0.964\n",
      "Training #18\n",
      "Epoch 00006: early stopping\n",
      "Layers: 3 [(50 tanh (0.5)), (100 tanh (0.5)), (250 relu (0.0))], Optimizer: adam, Accuracy 0.948, AUC 0.956\n",
      "Training #19\n",
      "Epoch 00020: early stopping\n",
      "Layers: 3 [(100 sigmoid (0.5)), (50 elu (0.5)), (50 relu (0.25))], Optimizer: adam, Accuracy 0.973, AUC 0.969\n",
      "Training #20\n",
      "Epoch 00010: early stopping\n",
      "Layers: 3 [(250 elu (0.25)), (250 sigmoid (0.5)), (250 tanh (0.5))], Optimizer: adam, Accuracy 0.959, AUC 0.956\n",
      "Training #21\n",
      "Epoch 00006: early stopping\n",
      "Layers: 3 [(250 elu (0.25)), (200 tanh (0.5)), (100 relu (0.0))], Optimizer: adam, Accuracy 0.975, AUC 0.957\n",
      "Training #22\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00012: early stopping\n",
      "Layers: 3 [(200 relu (0.25)), (100 relu (0.25)), (100 relu (0.0))], Optimizer: adam, Accuracy 0.964, AUC 0.968\n",
      "Training #23\n",
      "Epoch 00013: early stopping\n",
      "Layers: 3 [(100 elu (0.5)), (50 elu (0.25)), (55 relu (0.5))], Optimizer: adam, Accuracy 0.976, AUC 0.968\n",
      "Training #24\n",
      "Epoch 00007: early stopping\n",
      "Layers: 3 [(250 sigmoid (0.5)), (200 elu (0.5)), (200 relu (0.0))], Optimizer: adam, Accuracy 0.967, AUC 0.966\n",
      "Training #25\n",
      "Epoch 00017: early stopping\n",
      "Layers: 3 [(50 elu (0.25)), (200 elu (0.25)), (100 elu (0.25))], Optimizer: adam, Accuracy 0.985, AUC 0.967\n",
      "Training #26\n",
      "Epoch 00011: early stopping\n",
      "Layers: 3 [(100 sigmoid (0.0)), (100 relu (0.0)), (25 relu (0.25))], Optimizer: adam, Accuracy 0.892, AUC 0.956\n",
      "Training #27\n",
      "Epoch 00006: early stopping\n",
      "Layers: 3 [(100 elu (0.5)), (250 tanh (0.5)), (100 relu (0.5))], Optimizer: rmsprop, Accuracy 0.99, AUC 0.904\n",
      "Training #28\n",
      "Epoch 00020: early stopping\n",
      "Layers: 3 [(25 elu (0.25)), (50 elu (0.0)), (25 relu (0.5))], Optimizer: adam, Accuracy 0.979, AUC 0.965\n",
      "Training #29\n",
      "Epoch 00017: early stopping\n",
      "Layers: 3 [(25 elu (0.25)), (200 elu (0.0)), (25 elu (0.0))], Optimizer: adam, Accuracy 0.99, AUC 0.958\n",
      "Best:\n",
      "Layers: 3 [(100 sigmoid (0.5)), (50 elu (0.5)), (50 relu (0.25))], Optimizer: adam, Accuracy 0.973, AUC 0.969\n",
      "Layers: 3 [(100 sigmoid (0.25)), (250 relu (0.25)), (25 tanh (0.5))], Optimizer: adam, Accuracy 0.97, AUC 0.969\n",
      "Layers: 3 [(200 relu (0.25)), (100 relu (0.25)), (100 relu (0.0))], Optimizer: adam, Accuracy 0.964, AUC 0.968\n",
      "Generation 2\n",
      "Training #0\n",
      "Epoch 00006: early stopping\n",
      "Layers: 3 [(100 sigmoid (0.5)), (250 elu (0.5)), (50 relu (0.5))], Optimizer: adam, Accuracy 0.967, AUC 0.967\n",
      "Training #1\n",
      "Epoch 00013: early stopping\n",
      "Layers: 3 [(100 sigmoid (0.0)), (50 relu (0.5)), (100 relu (0.0))], Optimizer: adam, Accuracy 0.926, AUC 0.96\n",
      "Training #2\n",
      "Epoch 00011: early stopping\n",
      "Layers: 3 [(100 elu (0.5)), (200 elu (0.5)), (50 relu (0.0))], Optimizer: adam, Accuracy 0.978, AUC 0.966\n",
      "Training #3\n",
      "Epoch 00012: early stopping\n",
      "Layers: 3 [(200 relu (0.5)), (100 elu (0.25)), (25 elu (0.0))], Optimizer: adam, Accuracy 0.97, AUC 0.962\n",
      "Training #4\n",
      "Epoch 00031: early stopping\n",
      "Layers: 3 [(100 tanh (0.25)), (25 elu (0.5)), (50 relu (0.25))], Optimizer: adam, Accuracy 0.969, AUC 0.962\n",
      "Training #5\n",
      "Epoch 00006: early stopping\n",
      "Layers: 3 [(250 elu (0.5)), (250 elu (0.25)), (25 tanh (0.5))], Optimizer: adam, Accuracy 0.933, AUC 0.938\n",
      "Training #6\n",
      "Epoch 00013: early stopping\n",
      "Layers: 3 [(100 sigmoid (0.0)), (50 relu (0.5)), (250 relu (0.25))], Optimizer: adam, Accuracy 0.965, AUC 0.96\n",
      "Training #7\n",
      "Epoch 00008: early stopping\n",
      "Layers: 3 [(250 elu (0.25)), (25 sigmoid (0.25)), (25 relu (0.25))], Optimizer: adam, Accuracy 0.962, AUC 0.967\n",
      "Training #8\n",
      "Epoch 00011: early stopping\n",
      "Layers: 3 [(100 elu (0.5)), (200 sigmoid (0.5)), (25 relu (0.25))], Optimizer: adam, Accuracy 0.972, AUC 0.968\n",
      "Training #9\n",
      "Epoch 00022: early stopping\n",
      "Layers: 3 [(100 elu (0.5)), (100 relu (0.25)), (55 relu (0.25))], Optimizer: adam, Accuracy 0.965, AUC 0.964\n",
      "Training #10\n",
      "Epoch 00011: early stopping\n",
      "Layers: 3 [(100 tanh (0.25)), (200 tanh (0.25)), (25 sigmoid (0.5))], Optimizer: adam, Accuracy 0.958, AUC 0.963\n",
      "Training #11\n",
      "Epoch 00013: early stopping\n",
      "Layers: 3 [(200 elu (0.25)), (100 sigmoid (0.25)), (100 sigmoid (0.5))], Optimizer: adam, Accuracy 0.974, AUC 0.961\n",
      "Training #12\n",
      "Epoch 00016: early stopping\n",
      "Layers: 3 [(25 sigmoid (0.25)), (250 sigmoid (0.5)), (25 relu (0.25))], Optimizer: adam, Accuracy 0.975, AUC 0.962\n",
      "Training #13\n",
      "Epoch 00014: early stopping\n",
      "Layers: 3 [(50 elu (0.25)), (100 elu (0.5)), (100 sigmoid (0.0))], Optimizer: adam, Accuracy 0.964, AUC 0.966\n",
      "Training #14\n",
      "Epoch 00011: early stopping\n",
      "Layers: 3 [(50 tanh (0.5)), (25 elu (0.25)), (25 sigmoid (0.5))], Optimizer: adam, Accuracy 0.951, AUC 0.96\n",
      "Training #15\n",
      "Epoch 00007: early stopping\n",
      "Layers: 3 [(100 sigmoid (0.5)), (50 elu (0.0)), (200 relu (0.0))], Optimizer: adam, Accuracy 0.973, AUC 0.968\n",
      "Training #16\n",
      "Epoch 00008: early stopping\n",
      "Layers: 3 [(250 sigmoid (0.25)), (50 tanh (0.5)), (200 elu (0.25))], Optimizer: adam, Accuracy 0.961, AUC 0.968\n",
      "Training #17\n",
      "Epoch 00009: early stopping\n",
      "Layers: 3 [(200 elu (0.25)), (200 relu (0.25)), (250 relu (0.25))], Optimizer: adam, Accuracy 0.953, AUC 0.966\n",
      "Training #18\n",
      "Epoch 00022: early stopping\n",
      "Layers: 3 [(50 elu (0.0)), (200 elu (0.0)), (50 elu (0.25))], Optimizer: adam, Accuracy 0.987, AUC 0.954\n",
      "Training #19\n",
      "Epoch 00027: early stopping\n",
      "Layers: 3 [(25 elu (0.25)), (200 elu (0.25)), (200 relu (0.25))], Optimizer: adam, Accuracy 0.991, AUC 0.963\n",
      "Training #20\n",
      "Epoch 00006: early stopping\n",
      "Layers: 3 [(100 sigmoid (0.25)), (250 tanh (0.25)), (25 relu (0.0))], Optimizer: adam, Accuracy 0.964, AUC 0.969\n",
      "Training #21\n",
      "Epoch 00009: early stopping\n",
      "Layers: 3 [(250 sigmoid (0.5)), (250 relu (0.25)), (250 tanh (0.5))], Optimizer: adam, Accuracy 0.979, AUC 0.967\n",
      "Training #22\n",
      "Epoch 00015: early stopping\n",
      "Layers: 3 [(50 relu (0.25)), (25 relu (0.0)), (25 elu (0.25))], Optimizer: adam, Accuracy 0.979, AUC 0.967\n",
      "Training #23\n",
      "Epoch 00017: early stopping\n",
      "Layers: 3 [(25 elu (0.0)), (50 tanh (0.5)), (250 sigmoid (0.25))], Optimizer: adam, Accuracy 0.972, AUC 0.959\n",
      "Training #24\n",
      "Epoch 00011: early stopping\n",
      "Layers: 3 [(50 elu (0.0)), (50 sigmoid (0.25)), (25 relu (0.25))], Optimizer: adam, Accuracy 0.947, AUC 0.96\n",
      "Training #25\n",
      "Epoch 00013: early stopping\n",
      "Layers: 3 [(100 sigmoid (0.5)), (50 elu (0.5)), (25 relu (0.5))], Optimizer: adam, Accuracy 0.971, AUC 0.966\n",
      "Training #26\n",
      "Epoch 00007: early stopping\n",
      "Layers: 3 [(200 relu (0.5)), (100 tanh (0.25)), (100 relu (0.25))], Optimizer: adam, Accuracy 0.978, AUC 0.96\n",
      "Training #27\n",
      "Epoch 00018: early stopping\n",
      "Layers: 3 [(250 relu (0.5)), (200 relu (0.25)), (50 relu (0.0))], Optimizer: adam, Accuracy 0.974, AUC 0.966\n",
      "Training #28\n",
      "Epoch 00008: early stopping\n",
      "Layers: 3 [(50 sigmoid (0.25)), (250 tanh (0.5)), (25 sigmoid (0.5))], Optimizer: adam, Accuracy 0.958, AUC 0.965\n",
      "Training #29\n",
      "Epoch 00023: early stopping\n",
      "Layers: 3 [(50 elu (0.25)), (250 sigmoid (0.5)), (200 elu (0.25))], Optimizer: adam, Accuracy 0.985, AUC 0.963\n",
      "Best:\n",
      "Layers: 3 [(100 sigmoid (0.25)), (250 tanh (0.25)), (25 relu (0.0))], Optimizer: adam, Accuracy 0.964, AUC 0.969\n",
      "Layers: 3 [(100 sigmoid (0.5)), (50 elu (0.0)), (200 relu (0.0))], Optimizer: adam, Accuracy 0.973, AUC 0.968\n",
      "Layers: 3 [(100 elu (0.5)), (200 sigmoid (0.5)), (25 relu (0.25))], Optimizer: adam, Accuracy 0.972, AUC 0.968\n",
      "Generation 3\n",
      "Training #0\n",
      "Epoch 00014: early stopping\n",
      "Layers: 3 [(100 sigmoid (0.5)), (50 tanh (0.0)), (200 relu (0.5))], Optimizer: adam, Accuracy 0.962, AUC 0.968\n",
      "Training #1\n",
      "Epoch 00018: early stopping\n",
      "Layers: 3 [(100 elu (0.25)), (200 tanh (0.5)), (25 relu (0.25))], Optimizer: adam, Accuracy 0.973, AUC 0.963\n",
      "Training #2\n",
      "Epoch 00010: early stopping\n",
      "Layers: 3 [(250 tanh (0.25)), (50 tanh (0.25)), (50 elu (0.25))], Optimizer: adam, Accuracy 0.924, AUC 0.967\n",
      "Training #3\n",
      "Epoch 00015: early stopping\n",
      "Layers: 3 [(100 sigmoid (0.25)), (50 elu (0.0)), (200 relu (0.25))], Optimizer: adam, Accuracy 0.96, AUC 0.962\n",
      "Training #4\n",
      "Epoch 00011: early stopping\n",
      "Layers: 3 [(250 sigmoid (0.5)), (50 tanh (0.25)), (200 elu (0.25))], Optimizer: adam, Accuracy 0.96, AUC 0.96\n",
      "Training #5\n",
      "Epoch 00012: early stopping\n",
      "Layers: 3 [(50 relu (0.25)), (250 tanh (0.25)), (25 sigmoid (0.0))], Optimizer: adam, Accuracy 0.979, AUC 0.965\n",
      "Training #6\n",
      "Epoch 00009: early stopping\n",
      "Layers: 3 [(100 sigmoid (0.5)), (100 tanh (0.25)), (25 relu (0.25))], Optimizer: adam, Accuracy 0.957, AUC 0.965\n",
      "Training #7\n",
      "Epoch 00019: early stopping\n",
      "Layers: 3 [(250 elu (0.5)), (25 tanh (0.5)), (200 elu (0.25))], Optimizer: adam, Accuracy 0.98, AUC 0.934\n",
      "Training #8\n",
      "Epoch 00010: early stopping\n",
      "Layers: 3 [(250 sigmoid (0.5)), (100 sigmoid (0.25)), (250 relu (0.25))], Optimizer: adam, Accuracy 0.939, AUC 0.967\n",
      "Training #9\n",
      "Epoch 00012: early stopping\n",
      "Layers: 3 [(100 sigmoid (0.25)), (100 elu (0.0)), (25 relu (0.5))], Optimizer: adam, Accuracy 0.973, AUC 0.968\n",
      "Training #10\n",
      "Epoch 00008: early stopping\n",
      "Layers: 3 [(250 sigmoid (0.25)), (50 elu (0.25)), (200 relu (0.25))], Optimizer: adam, Accuracy 0.962, AUC 0.966\n",
      "Training #11\n",
      "Epoch 00007: early stopping\n",
      "Layers: 3 [(50 elu (0.5)), (25 sigmoid (0.0)), (25 relu (0.5))], Optimizer: adam, Accuracy 0.964, AUC 0.966\n",
      "Training #12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00016: early stopping\n",
      "Layers: 3 [(50 sigmoid (0.25)), (25 relu (0.5)), (100 elu (0.25))], Optimizer: adam, Accuracy 0.974, AUC 0.965\n",
      "Training #13\n",
      "Epoch 00010: early stopping\n",
      "Layers: 3 [(250 sigmoid (0.25)), (200 relu (0.5)), (25 tanh (0.5))], Optimizer: adam, Accuracy 0.951, AUC 0.965\n",
      "Training #14\n",
      "Epoch 00008: early stopping\n",
      "Layers: 3 [(100 sigmoid (0.5)), (250 elu (0.25)), (25 relu (0.25))], Optimizer: adam, Accuracy 0.921, AUC 0.965\n",
      "Training #15\n",
      "Epoch 00014: early stopping\n",
      "Layers: 3 [(250 sigmoid (0.25)), (250 tanh (0.5)), (250 elu (0.5))], Optimizer: adam, Accuracy 0.968, AUC 0.962\n",
      "Training #16\n",
      "Epoch 00009: early stopping\n",
      "Layers: 3 [(100 elu (0.25)), (25 elu (0.25)), (200 sigmoid (0.25))], Optimizer: adam, Accuracy 0.963, AUC 0.965\n",
      "Training #17\n",
      "Epoch 00009: early stopping\n",
      "Layers: 3 [(250 sigmoid (0.25)), (250 relu (0.5)), (25 relu (0.0))], Optimizer: adam, Accuracy 0.947, AUC 0.964\n",
      "Training #18\n",
      "Epoch 00011: early stopping\n",
      "Layers: 3 [(250 elu (0.25)), (200 elu (0.25)), (250 relu (0.25))], Optimizer: adam, Accuracy 0.972, AUC 0.967\n",
      "Training #19\n",
      "Epoch 00009: early stopping\n",
      "Layers: 3 [(100 elu (0.25)), (25 tanh (0.25)), (200 elu (0.25))], Optimizer: adam, Accuracy 0.96, AUC 0.959\n",
      "Training #20\n",
      "Epoch 00019: early stopping\n",
      "Layers: 3 [(100 relu (0.5)), (250 elu (0.0)), (50 relu (0.5))], Optimizer: adam, Accuracy 0.988, AUC 0.967\n",
      "Training #21\n",
      "Epoch 00013: early stopping\n",
      "Layers: 3 [(100 tanh (0.25)), (50 elu (0.5)), (100 tanh (0.0))], Optimizer: adam, Accuracy 0.958, AUC 0.968\n",
      "Training #22\n",
      "Epoch 00008: early stopping\n",
      "Layers: 3 [(50 relu (0.5)), (250 relu (0.5)), (250 elu (0.25))], Optimizer: adam, Accuracy 0.99, AUC 0.95\n",
      "Training #23\n",
      "Epoch 00010: early stopping\n",
      "Layers: 3 [(50 elu (0.5)), (200 sigmoid (0.5)), (25 relu (0.5))], Optimizer: adam, Accuracy 0.965, AUC 0.964\n",
      "Training #24\n",
      "Epoch 00009: early stopping\n",
      "Layers: 3 [(100 elu (0.25)), (200 elu (0.0)), (100 relu (0.0))], Optimizer: adam, Accuracy 0.974, AUC 0.962\n",
      "Training #25\n",
      "Epoch 00011: early stopping\n",
      "Layers: 3 [(100 relu (0.25)), (100 tanh (0.5)), (250 relu (0.0))], Optimizer: adam, Accuracy 0.974, AUC 0.968\n",
      "Training #26\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-65548d2f0ae7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Save all populations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-f12af3baacb3>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(population)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpopulation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training #{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-cef033e14f22>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m     88\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                         class_weight=cw)\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1002\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for generation in range(N_GENERATIONS):\n",
    "    print(\"Generation {}\".format(generation))\n",
    "    \n",
    "    # Train\n",
    "    train(population)\n",
    "    \n",
    "    # Save all populations\n",
    "    population_history.extend(population)\n",
    "    \n",
    "    # Sort networks by accuracy\n",
    "    population = sorted(population, key=lambda x: x.auc, reverse=True)\n",
    "    \n",
    "    print(\"Best:\")\n",
    "    for network in population[:3]:\n",
    "        print (network)\n",
    "\n",
    "    # All possible combinations of parents\n",
    "    parents = itertools.combinations(population, 2)\n",
    "    \n",
    "    # Sort combination of parents by sum of their auc scores\n",
    "    parents = sorted(parents, key=lambda x: sum(n.auc for n in x), reverse=True)\n",
    "    \n",
    "    next_generation = []\n",
    "    \n",
    "    for (parent1, parent2) in parents:\n",
    "        child = crossover(parent1, parent2)\n",
    "        \n",
    "        # Do not add same networks\n",
    "        if child not in next_generation:\n",
    "            \n",
    "            # Check if child was in ever history\n",
    "            if child in population_history:\n",
    "                child_index = population_history.index(child)\n",
    "                child = population_history[child_index]\n",
    "            else:\n",
    "                child.compile_model()\n",
    "                \n",
    "            next_generation.append(child)\n",
    "            \n",
    "            if len(next_generation) >= POPULATION_SIZE:\n",
    "                break\n",
    "    \n",
    "    population = next_generation\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layers: 3 [(100 sigmoid (0.5)), (50 elu (0.5)), (50 relu (0.25))], Optimizer: adam, Accuracy 0.973, AUC 0.969\n",
      "Layers: 3 [(100 sigmoid (0.25)), (250 tanh (0.25)), (25 relu (0.0))], Optimizer: adam, Accuracy 0.964, AUC 0.969\n",
      "Layers: 3 [(100 sigmoid (0.25)), (250 relu (0.25)), (25 tanh (0.5))], Optimizer: adam, Accuracy 0.97, AUC 0.969\n",
      "Layers: 3 [(100 sigmoid (0.5)), (50 elu (0.0)), (200 relu (0.0))], Optimizer: adam, Accuracy 0.973, AUC 0.968\n",
      "Layers: 3 [(100 elu (0.5)), (200 sigmoid (0.5)), (25 relu (0.25))], Optimizer: adam, Accuracy 0.972, AUC 0.968\n",
      "Layers: 3 [(200 relu (0.25)), (100 relu (0.25)), (100 relu (0.0))], Optimizer: adam, Accuracy 0.964, AUC 0.968\n",
      "Layers: 3 [(250 sigmoid (0.25)), (50 tanh (0.5)), (200 elu (0.25))], Optimizer: adam, Accuracy 0.961, AUC 0.968\n",
      "Layers: 3 [(100 elu (0.5)), (50 elu (0.25)), (55 relu (0.5))], Optimizer: adam, Accuracy 0.976, AUC 0.968\n",
      "Layers: 3 [(50 relu (0.25)), (25 relu (0.0)), (25 elu (0.25))], Optimizer: adam, Accuracy 0.979, AUC 0.967\n",
      "Layers: 3 [(50 elu (0.25)), (25 relu (0.25)), (25 sigmoid (0.25))], Optimizer: adam, Accuracy 0.961, AUC 0.967\n",
      "Layers: 3 [(250 sigmoid (0.5)), (250 relu (0.25)), (250 tanh (0.5))], Optimizer: adam, Accuracy 0.979, AUC 0.967\n",
      "Layers: 3 [(50 elu (0.25)), (200 elu (0.25)), (100 elu (0.25))], Optimizer: adam, Accuracy 0.985, AUC 0.967\n",
      "Layers: 3 [(250 elu (0.25)), (25 sigmoid (0.25)), (25 relu (0.25))], Optimizer: adam, Accuracy 0.962, AUC 0.967\n",
      "Layers: 3 [(25 elu (0.25)), (200 sigmoid (0.5)), (200 relu (0.25))], Optimizer: adam, Accuracy 0.965, AUC 0.967\n",
      "Layers: 3 [(100 sigmoid (0.5)), (250 elu (0.5)), (50 relu (0.5))], Optimizer: adam, Accuracy 0.967, AUC 0.967\n",
      "Layers: 3 [(200 elu (0.25)), (200 relu (0.25)), (250 relu (0.25))], Optimizer: adam, Accuracy 0.953, AUC 0.966\n",
      "Layers: 3 [(250 sigmoid (0.5)), (50 tanh (0.25)), (200 relu (0.25))], Optimizer: adam, Accuracy 0.979, AUC 0.966\n",
      "Layers: 3 [(250 sigmoid (0.5)), (200 elu (0.5)), (200 relu (0.0))], Optimizer: adam, Accuracy 0.967, AUC 0.966\n",
      "Layers: 3 [(50 elu (0.25)), (100 elu (0.5)), (100 sigmoid (0.0))], Optimizer: adam, Accuracy 0.964, AUC 0.966\n",
      "Layers: 3 [(100 elu (0.5)), (200 elu (0.5)), (50 relu (0.0))], Optimizer: adam, Accuracy 0.978, AUC 0.966\n",
      "Layers: 3 [(250 relu (0.5)), (200 relu (0.25)), (50 relu (0.0))], Optimizer: adam, Accuracy 0.974, AUC 0.966\n",
      "Layers: 3 [(100 sigmoid (0.5)), (50 elu (0.5)), (25 relu (0.5))], Optimizer: adam, Accuracy 0.971, AUC 0.966\n",
      "Layers: 3 [(200 elu (0.0)), (50 tanh (0.5)), (250 sigmoid (0.25))], Optimizer: adam, Accuracy 0.968, AUC 0.965\n",
      "Layers: 3 [(25 elu (0.25)), (50 elu (0.0)), (25 relu (0.5))], Optimizer: adam, Accuracy 0.979, AUC 0.965\n",
      "Layers: 3 [(50 sigmoid (0.25)), (250 tanh (0.5)), (25 sigmoid (0.5))], Optimizer: adam, Accuracy 0.958, AUC 0.965\n",
      "Layers: 3 [(250 tanh (0.5)), (25 tanh (0.5)), (25 elu (0.25))], Optimizer: adam, Accuracy 0.948, AUC 0.964\n",
      "Layers: 3 [(50 sigmoid (0.25)), (25 relu (0.25)), (25 relu (0.25))], Optimizer: adam, Accuracy 0.979, AUC 0.964\n",
      "Layers: 3 [(100 elu (0.25)), (100 tanh (0.25)), (100 sigmoid (0.0))], Optimizer: adam, Accuracy 0.97, AUC 0.964\n",
      "Layers: 3 [(100 elu (0.5)), (100 relu (0.25)), (55 relu (0.25))], Optimizer: adam, Accuracy 0.965, AUC 0.964\n",
      "Layers: 3 [(200 tanh (0.25)), (25 tanh (0.25)), (25 tanh (0.0))], Optimizer: adam, Accuracy 0.963, AUC 0.964\n"
     ]
    }
   ],
   "source": [
    "population_history = sorted(population_history, key=lambda x: x.auc, reverse=True)\n",
    "\n",
    "for network in population_history[:30]:\n",
    "    print(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save history\n",
    "with open(\"history.json\", 'w') as o:\n",
    "    json.dump([network.to_json() for network in population_history], o, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mantas/.local/lib/python3.6/site-packages/watermark/watermark.py:155: DeprecationWarning: Importing scikit-learn as `scikit-learn` has been depracated and will not be supported anymore in v1.7.0. Please use the package name `sklearn` instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mantas Stankevicius 2018-11-06 \n",
      "\n",
      "CPython 3.6.5\n",
      "IPython 7.1.1\n",
      "\n",
      "numpy 1.14.3\n",
      "sklearn 0.19.1\n",
      "tensorflow 1.8.0\n",
      "keras 2.1.6\n",
      "h5py 2.7.1\n",
      "\n",
      "compiler   : GCC 7.3.0\n",
      "system     : Linux\n",
      "release    : 4.15.0-36-generic\n",
      "machine    : x86_64\n",
      "processor  : x86_64\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%watermark -a \"Mantas Stankevicius\" -d -v -m -p numpy,scikit-learn,tensorflow,keras,h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
